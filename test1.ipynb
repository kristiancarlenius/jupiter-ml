{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "import datetime\n",
    "from io import StringIO\n",
    "import random\n",
    "#!{sys.executable} -m pip install xgboost\n",
    "rs = 420\n",
    "random.seed(rs)\n",
    "\n",
    "print(datetime.datetime.today().strftime(\"%HH:%MM %dd\"))\n",
    "# Load datasets\n",
    "\n",
    "featuers = ['vesselId', 'hour', 'day', 'month', 'minute', 'vesselType', 'yearBuilt', 'length', 'breadth', 'CEU', 'DWT', 'GT', 'portLatitude', 'portLongitude', 'hour_sch', 'day_sch', 'month_sch', 'minute_sch', 'lat_shift_1', 'lon_shift_1', 'minute_shift_1', 'hour_shift_1', 'day_shift_1', 'month_shift_1', 'cog_1', 'heading_1', 'lat_shift_2', 'lon_shift_2', 'minute_shift_2', 'hour_shift_2', 'day_shift_2', 'month_shift_2', 'cog_2', 'heading_2', 'lat_shift_3', 'lon_shift_3', 'minute_shift_3', 'hour_shift_3', 'day_shift_3', 'month_shift_3', 'cog_3', 'heading_3', 'cog', 'heading']\n",
    "vessel_encoder = LabelEncoder()\n",
    "# Train-test split\n",
    "liste = []\n",
    "for i in range(len(featuers)):\n",
    "    liste.append(pd.read_csv('x_data_'+str(i)+'.csv', sep=','))\n",
    "\n",
    "X = liste[0].join(liste[1:])\n",
    "y_1 = pd.read_csv('y_data_1.csv', sep=',')\n",
    "y_2 = pd.read_csv('y_data_2.csv', sep=',')\n",
    "y = y_2.join(y_1)\n",
    "\n",
    "print(\"p6:\", X.tail())\n",
    "print(\"p7:\", y.tail())\n",
    "X['vesselId'] = vessel_encoder.fit_transform(X['vesselId'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=rs)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=180, random_state=rs)\n",
    "# Train a RandomForest model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Absolute Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {np.sqrt(mse)}')\n",
    "print(f'R2-score: {r2_score(y_val, y_pred)}')\n",
    "print(f'Variance Score: {explained_variance_score(y_val, y_pred)}')\n",
    "\n",
    "# Use the same features as training\n",
    "X_0 = pd.read_csv('x_test.csv', sep=',')\n",
    "X_1 = pd.read_csv('x_test_1.csv', sep=',')\n",
    "X_2 = pd.read_csv('x_test_2.csv', sep=',')\n",
    "X_3 = pd.read_csv('x_test_3.csv', sep=',')\n",
    "X_4 = pd.read_csv('x_test_4.csv', sep=',')\n",
    "X_test = X_0.join([X_1, X_2, X_3, X_4])\n",
    "X_test = X_test[featuers]\n",
    "X_test['vesselId'] = vessel_encoder.transform(X_test['vesselId'])\n",
    "# Scale the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Save the predictions\n",
    "predictions_df = pd.DataFrame(test_predictions, columns=['longitude_predicted', 'latitude_predicted'])\n",
    "predictions_df.to_csv('ais_test_predictions_2.csv', index=True)\n",
    "print(datetime.datetime.today().strftime(\"%HH:%MM %dd\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20H:33M 24d\n",
      "p6:          vesselId  hour  day  month  minute  vesselType  length  breadth   \n",
      "1522060       682    23    7      5      59        83.0  182.00     25.0  \\\n",
      "1522061        85    23    7      5      59        83.0  199.00     32.0   \n",
      "1522062       459    23    7      5      59        83.0  199.96     38.0   \n",
      "1522063       596    23    7      5      59        21.0  186.00     27.0   \n",
      "1522064       637    23    7      5      59        83.0  200.00     32.0   \n",
      "\n",
      "          CEU      DWT  ...  lon_shift_4  lat_shift_5  lon_shift_5    cog   \n",
      "1522060   300  12502.0  ...     -5.84482     51.09372     -5.84536  359.1  \\\n",
      "1522061  6354  22160.0  ...    -12.10865     38.47765    -12.13535   12.3   \n",
      "1522062  7429  18241.0  ...     -4.66703     49.77723     -4.50058  269.8   \n",
      "1522063  1400   7150.0  ...     10.29855     37.64190     11.32413    8.0   \n",
      "1522064  6215  18907.0  ...    -74.95443     38.70218    -74.90653  336.0   \n",
      "\n",
      "         heading  time_diff_1  time_diff_2  time_diff_3  time_diff_4   \n",
      "1522060        1       7268.0       1046.0       6312.0       1169.0  \\\n",
      "1522061       13       1224.0       1242.0       1260.0       1254.0   \n",
      "1522062      270       1224.0       1242.0       1254.0       1260.0   \n",
      "1522063        6      29783.0        602.0       5711.0      21956.0   \n",
      "1522064      337       1218.0       1251.0       1259.0       1240.0   \n",
      "\n",
      "         time_diff_5  \n",
      "1522060       6259.0  \n",
      "1522061       1236.0  \n",
      "1522062       1218.0  \n",
      "1522063        769.0  \n",
      "1522064       1220.0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "p7:          longitude  latitude\n",
      "1522060   -5.82223  52.19131\n",
      "1522061  -12.00502  38.96142\n",
      "1522062   -5.22042  49.71372\n",
      "1522063   10.78280  38.27895\n",
      "1522064  -75.13275  38.98635\n",
      "Mean Absolute Error: 11.233840929863215\n",
      "Root Mean Squared Error: 3.3516922486802416\n",
      "R2-score: 0.9961349630450355\n",
      "Variance Score: 0.9961359172059716\n",
      "20H:37M 24d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "rs = 420\n",
    "random.seed(rs)\n",
    "\n",
    "print(datetime.datetime.today().strftime(\"%HH:%MM %dd\"))\n",
    "\n",
    "featuers = ['vesselId', 'hour', 'day', 'month', 'minute', 'vesselType', 'yearBuilt', 'length', 'breadth', 'CEU', 'DWT', 'GT', 'portLatitude', 'portLongitude', 'hour_sch', 'day_sch', 'month_sch', 'minute_sch', 'lat_shift_1', 'lon_shift_1', 'minute_shift_1', 'hour_shift_1', 'day_shift_1', 'month_shift_1', 'cog_1', 'heading_1', 'lat_shift_2', 'lon_shift_2', 'minute_shift_2', 'hour_shift_2', 'day_shift_2', 'month_shift_2', 'cog_2', 'heading_2', 'lat_shift_3', 'lon_shift_3', 'minute_shift_3', 'hour_shift_3', 'day_shift_3', 'month_shift_3', 'cog_3', 'heading_3', 'lat_shift_4', 'lon_shift_4', 'minute_shift_4', 'hour_shift_4', 'day_shift_4', 'month_shift_4', 'cog_4', 'heading_4', 'lat_shift_5', 'lon_shift_5', 'minute_shift_5', 'hour_shift_5', 'day_shift_5', 'month_shift_5', 'cog_5', 'heading_5', 'cog', 'heading', 'time_diff_1', 'time_diff_2', 'time_diff_3', 'time_diff_4', 'time_diff_5', 'time_diff']\n",
    "vessel_encoder = LabelEncoder()\n",
    "timesteps = 5\n",
    "# test-test split\n",
    "liste = []\n",
    "for i in range(len(featuers)):\n",
    "    liste.append(pd.read_csv('x_data_'+str(i)+'.csv', sep=','))\n",
    "\n",
    "featuers = ['vesselId', 'lat_shift_1', 'lon_shift_1', 'lat_shift_2', 'lon_shift_2', 'lat_shift_3', 'lon_shift_3', 'time_diff', 'time_diff_1', 'time_diff_2']\n",
    "X = liste[0].join(liste[1:])\n",
    "X['vesselId'] = vessel_encoder.fit_transform(X['vesselId'])\n",
    "X = X[featuers]\n",
    "print(X.tail(1))\n",
    "y_1 = pd.read_csv('y_data_1.csv', sep=',')\n",
    "y_2 = pd.read_csv('y_data_2.csv', sep=',')\n",
    "y = y_2.join(y_1)\n",
    "\n",
    "X_0 = pd.read_csv('x_test.csv', sep=',')\n",
    "X_1 = pd.read_csv('x_test_1.csv', sep=',')\n",
    "X_2 = pd.read_csv('x_test_2.csv', sep=',')\n",
    "X_3 = pd.read_csv('x_test_3.csv', sep=',')\n",
    "X_4 = pd.read_csv('x_test_4.csv', sep=',')\n",
    "X_test = X_0.join([X_1, X_2, X_3, X_4])\n",
    "X_test = X_test[featuers]\n",
    "\n",
    "model = ExtraTreesRegressor(n_estimators=180, random_state=rs)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X)\n",
    "# Train a RandomForest model\n",
    "model.fit(X_train, y)\n",
    "\n",
    "\n",
    "def sjekk(liste):\n",
    "        nyliste = [0, 0]\n",
    "        flag = 0\n",
    "        #print('longitude error:', liste[0])\n",
    "        if(liste[0]<-180):\n",
    "            nyliste[0] = 180+(liste[0]+180)\n",
    "        elif(liste[0]>180):\n",
    "            nyliste[0] = -180+(liste[0]-180)\n",
    "        else:\n",
    "            flag = 1\n",
    "            nyliste[0] = liste[0]\n",
    "\n",
    "        if(liste[1]<-90):\n",
    "            nyliste[1] = -90-(liste[1]+90)\n",
    "        elif(liste[1]>90):\n",
    "            nyliste[1] = 90-(liste[1]-90)\n",
    "        else:\n",
    "            nyliste[1] = liste[1]\n",
    "            flag = 1\n",
    "        \n",
    "        if(flag==0):\n",
    "            print(\"Value exceided lat lon\")\n",
    "\n",
    "        return nyliste\n",
    "\n",
    "results_with_index = []\n",
    "dictlast = {}\n",
    "    # Group by vesselId to process each vessel's data independently\n",
    "for idx, row in X_test.iterrows():\n",
    "    # Prepare test data for this vessel and retain original index\n",
    "    row.to_frame()\n",
    "    print(row)\n",
    "    if row['vesselId'] in dictlast:\n",
    "        row['lat_shift_3'] = row['lat_shift_2'] \n",
    "        row['lon_shift_3'] = row['lon_shift_2']\n",
    "        row['lat_shift_2'] = row['lat_shift_1']\n",
    "        row['lon_shift_2'] = row['lon_shift_1'] \n",
    "        row['lat_shift_1'] = dictlast[row['vesselId']][1]\n",
    "        row['lon_shift_1'] = dictlast[row['vesselId']][0]\n",
    "        \n",
    "        \n",
    "    result = model.predict(row.array.reshape(1, -1))\n",
    "    print(result)\n",
    "    result = sjekk(result[0])\n",
    "    dictlast[row['vesselId']] = result\n",
    "    results_with_index.append([idx, result[0], result[1]])\n",
    "    #print(results_with_index)\n",
    "\n",
    "# Concatenate results and sort by original order of ais_test\n",
    "final_predictions = pd.DataFrame(results_with_index, columns=['ID', 'longitude_predicted', 'latitude_predicted'])\n",
    "print(len(final_predictions['ID']))\n",
    "print(final_predictions)\n",
    "print(\"Latitude: max, min\", final_predictions['latitude_predicted'].max(), final_predictions['latitude_predicted'].min())\n",
    "print(\"Longitude: max, min\", final_predictions['longitude_predicted'].max(), final_predictions['longitude_predicted'].min())\n",
    "# Save the predictions\n",
    "final_predictions.to_csv('ais_test_predictions_6.csv', index=False)\n",
    "print(datetime.datetime.today().strftime(\"%HH:%MM %dd\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

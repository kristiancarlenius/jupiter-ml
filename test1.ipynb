{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20H:33M 24d\n",
      "p6:          vesselId  hour  day  month  minute  vesselType  length  breadth   \n",
      "1522060       682    23    7      5      59        83.0  182.00     25.0  \\\n",
      "1522061        85    23    7      5      59        83.0  199.00     32.0   \n",
      "1522062       459    23    7      5      59        83.0  199.96     38.0   \n",
      "1522063       596    23    7      5      59        21.0  186.00     27.0   \n",
      "1522064       637    23    7      5      59        83.0  200.00     32.0   \n",
      "\n",
      "          CEU      DWT  ...  lon_shift_4  lat_shift_5  lon_shift_5    cog   \n",
      "1522060   300  12502.0  ...     -5.84482     51.09372     -5.84536  359.1  \\\n",
      "1522061  6354  22160.0  ...    -12.10865     38.47765    -12.13535   12.3   \n",
      "1522062  7429  18241.0  ...     -4.66703     49.77723     -4.50058  269.8   \n",
      "1522063  1400   7150.0  ...     10.29855     37.64190     11.32413    8.0   \n",
      "1522064  6215  18907.0  ...    -74.95443     38.70218    -74.90653  336.0   \n",
      "\n",
      "         heading  time_diff_1  time_diff_2  time_diff_3  time_diff_4   \n",
      "1522060        1       7268.0       1046.0       6312.0       1169.0  \\\n",
      "1522061       13       1224.0       1242.0       1260.0       1254.0   \n",
      "1522062      270       1224.0       1242.0       1254.0       1260.0   \n",
      "1522063        6      29783.0        602.0       5711.0      21956.0   \n",
      "1522064      337       1218.0       1251.0       1259.0       1240.0   \n",
      "\n",
      "         time_diff_5  \n",
      "1522060       6259.0  \n",
      "1522061       1236.0  \n",
      "1522062       1218.0  \n",
      "1522063        769.0  \n",
      "1522064       1220.0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "p7:          longitude  latitude\n",
      "1522060   -5.82223  52.19131\n",
      "1522061  -12.00502  38.96142\n",
      "1522062   -5.22042  49.71372\n",
      "1522063   10.78280  38.27895\n",
      "1522064  -75.13275  38.98635\n",
      "Mean Absolute Error: 11.233840929863215\n",
      "Root Mean Squared Error: 3.3516922486802416\n",
      "R2-score: 0.9961349630450355\n",
      "Variance Score: 0.9961359172059716\n",
      "20H:37M 24d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "import datetime\n",
    "from io import StringIO\n",
    "import random\n",
    "#!{sys.executable} -m pip install xgboost\n",
    "rs = 420\n",
    "random.seed(rs)\n",
    "\n",
    "print(datetime.datetime.today().strftime(\"%HH:%MM %dd\"))\n",
    "# Load datasets\n",
    "\n",
    "featuers = ['vesselId', 'hour', 'day', 'month', 'minute', 'vesselType', 'yearBuilt', 'length', 'breadth', 'CEU', 'DWT', 'GT', 'portLatitude', 'portLongitude', 'hour_sch', 'day_sch', 'month_sch', 'minute_sch', 'lat_shift_1', 'lon_shift_1', 'minute_shift_1', 'hour_shift_1', 'day_shift_1', 'month_shift_1', 'cog_1', 'heading_1', 'lat_shift_2', 'lon_shift_2', 'minute_shift_2', 'hour_shift_2', 'day_shift_2', 'month_shift_2', 'cog_2', 'heading_2', 'lat_shift_3', 'lon_shift_3', 'minute_shift_3', 'hour_shift_3', 'day_shift_3', 'month_shift_3', 'cog_3', 'heading_3', 'lat_shift_4', 'lon_shift_4', 'minute_shift_4', 'hour_shift_4', 'day_shift_4', 'month_shift_4', 'cog_4', 'heading_4', 'lat_shift_5', 'lon_shift_5', 'minute_shift_5', 'hour_shift_5', 'day_shift_5', 'month_shift_5', 'cog_5', 'heading_5', 'cog', 'heading', 'time_diff_1', 'time_diff_2', 'time_diff_3', 'time_diff_4', 'time_diff_5']\n",
    "featuers2 = ['longitude', 'latitude', 'vesselId', 'hour', 'day', 'month', 'minute', 'vesselType', 'length', 'breadth', 'CEU', 'DWT', 'GT', 'portLatitude', 'portLongitude', 'lat_shift_1', 'lon_shift_1', 'lat_shift_2', 'lon_shift_2', 'lat_shift_3', 'lon_shift_3', 'lat_shift_4', 'lon_shift_4', 'lat_shift_5', 'lon_shift_5', 'time_diff_1', 'time_diff_2', 'time_diff_3', 'time_diff_4', 'time_diff_5']\n",
    "target2 = ['cog', 'heading']\n",
    "vessel_encoder = LabelEncoder()\n",
    "timesteps = 6\n",
    "# test-test split\n",
    "liste = []\n",
    "for i in range(len(featuers)):\n",
    "    liste.append(pd.read_csv('x_data_'+str(i)+'.csv', sep=','))\n",
    "\n",
    "featuers = ['vesselId', 'hour', 'day', 'month', 'minute', 'vesselType', 'length', 'breadth', 'CEU', 'DWT', 'GT', 'portLatitude', 'portLongitude', 'lat_shift_1', 'lon_shift_1', 'lat_shift_2', 'lon_shift_2', 'lat_shift_3', 'lon_shift_3', 'lat_shift_4', 'lon_shift_4', 'lat_shift_5', 'lon_shift_5', 'cog', 'heading', 'time_diff_1', 'time_diff_2', 'time_diff_3', 'time_diff_4', 'time_diff_5']\n",
    "X = liste[0].join(liste[1:])\n",
    "X = X[featuers]\n",
    "y_1 = pd.read_csv('y_data_1.csv', sep=',')\n",
    "y_2 = pd.read_csv('y_data_2.csv', sep=',')\n",
    "y = y_2.join(y_1)\n",
    "\n",
    "z = y.join(X)\n",
    "x2 = z[featuers2]\n",
    "y2 = z[target2]\n",
    "\n",
    "\n",
    "print(\"p6:\", X.tail())\n",
    "print(\"p7:\", y.tail())\n",
    "#TODO: create a second model, this one predicts the cog and heading, then after the prediction on the ais_test with both models, use it to update the shifted values to create a new prediction using the original model\n",
    "\n",
    "X['vesselId'] = vessel_encoder.fit_transform(X['vesselId'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01, random_state=rs)\n",
    "\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(x2, y2, test_size=0.01, random_state=rs)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "X_train_scaled2 = scaler2.fit_transform(X_train2)\n",
    "X_val_scaled2 = scaler2.transform(X_val2)\n",
    "\n",
    "\n",
    "model = ExtraTreesRegressor(n_estimators=1, random_state=rs)\n",
    "model2 = ExtraTreesRegressor(n_estimators=1, random_state=rs)\n",
    "# Train a RandomForest model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "model2.fit(X_train_scaled2, y_train2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Absolute Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {np.sqrt(mse)}')\n",
    "print(f'R2-score: {r2_score(y_val, y_pred)}')\n",
    "print(f'Variance Score: {explained_variance_score(y_val, y_pred)}')\n",
    "\n",
    "# Use the same features as training\n",
    "X_0 = pd.read_csv('x_test.csv', sep=',')\n",
    "X_1 = pd.read_csv('x_test_1.csv', sep=',')\n",
    "X_2 = pd.read_csv('x_test_2.csv', sep=',')\n",
    "X_3 = pd.read_csv('x_test_3.csv', sep=',')\n",
    "X_4 = pd.read_csv('x_test_4.csv', sep=',')\n",
    "X_test = X_0.join([X_1, X_2, X_3, X_4])\n",
    "X_test = X_test[featuers]\n",
    "X_test['vesselId'] = vessel_encoder.transform(X_test['vesselId'])\n",
    "\n",
    "X_test.to_excel(\"x_test.xlsx\")\n",
    "# Scale the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Save the predictions\n",
    "predictions_df = pd.DataFrame(test_predictions, columns=['longitude', 'latitude'])\n",
    "last = X_test.join(predictions_df)\n",
    "X_test2 = X_test.join(predictions_df)\n",
    "\n",
    "for i in range(1, timesteps):  # Only 3 previous time steps\n",
    "    X_test2[f'lat_shift_{i}'] = X_test2.groupby('vesselId')['latitude'].shift(i)\n",
    "    X_test2[f'lon_shift_{i}'] = X_test2.groupby('vesselId')['longitude'].shift(i)\n",
    "    #X_test2[f'minute_shift_{i}'] = X_test2.groupby('vesselId')['minute'].shift(i)\n",
    "    #X_test2[f'hour_shift_{i}'] = X_test2.groupby('vesselId')['hour'].shift(i)\n",
    "    #X_test2[f'day_shift_{i}'] = X_test2.groupby('vesselId')['day'].shift(i)\n",
    "\n",
    "    X_test2[f'lat_shift_{i}'] = np.where(X_test2[f'lat_shift_{i}'].isna(), last[f'lat_shift_{i}'], X_test2[f'lat_shift_{i}'])\n",
    "    X_test2[f'lon_shift_{i}'] = np.where(X_test2[f'lon_shift_{i}'].isna(), last[f'lon_shift_{i}'], X_test2[f'lon_shift_{i}'])\n",
    "    #X_test2[f'minute_shift_{i}'] = np.where(X_test2[f'minute_shift_{i}'].isna(), last[f'minute_shift_{i}'], X_test2[f'minute_shift_{i}'])\n",
    "    #X_test2[f'hour_shift_{i}'] = np.where(X_test2[f'hour_shift_{i}'].isna(), last[f'hour_shift_{i}'], X_test2[f'hour_shift_{i}'])\n",
    "    #X_test2[f'day_shift_{i}'] = np.where(X_test2[f'day_shift_{i}'].isna(), last[f'day_shift_{i}'], X_test2[f'day_shift_{i}'])\n",
    "\n",
    "last = X_test2[featuers]\n",
    "X_test2 = X_test2[featuers2]\n",
    "X_test_scaled2 = scaler2.transform(X_test2)\n",
    "#TODO: use predictions_df in the slides for the next two predicts\n",
    "\n",
    "\n",
    "test_predictions2 = model2.predict(X_test_scaled2)\n",
    "headercogup = pd.DataFrame(test_predictions2, columns=target2)\n",
    "\n",
    "last['cog'] = headercogup['cog']\n",
    "last['heading'] = headercogup['heading']\n",
    "\n",
    "last.to_excel(\"last.xlsx\")\n",
    "\n",
    "last_scaled = scaler.transform(last)\n",
    "\n",
    "final_prediction = model.predict(last_scaled)\n",
    "\n",
    "predictions_df = pd.DataFrame(final_prediction, columns=['longitude_predicted', 'latitude_predicted'])\n",
    "predictions_df.to_csv('ais_test_predictions_1.csv', index=True)\n",
    "print(datetime.datetime.today().strftime(\"%HH:%MM %dd\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

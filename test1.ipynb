{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19H:40M 23d\n",
      "p6:          vesselId  hour  day  month  minute  vesselType  yearBuilt  length   \n",
      "1522060       682    23    7      5      59        83.0       2000  182.00  \\\n",
      "1522061        85    23    7      5      59        83.0       2009  199.00   \n",
      "1522062       459    23    7      5      59        83.0       2017  199.96   \n",
      "1522063       596    23    7      5      59        21.0       2003  186.00   \n",
      "1522064       637    23    7      5      59        83.0       2011  200.00   \n",
      "\n",
      "         breadth   CEU  ...  minute_shift_4  hour_shift_4  day_shift_4   \n",
      "1522060     25.0   300  ...            34.0          19.0          7.0  \\\n",
      "1522061     32.0  6354  ...            36.0          22.0          7.0   \n",
      "1522062     38.0  7429  ...            36.0          22.0          7.0   \n",
      "1522063     27.0  1400  ...            32.0          13.0          7.0   \n",
      "1522064     32.0  6215  ...            36.0          22.0          7.0   \n",
      "\n",
      "         lat_shift_5  lon_shift_5  minute_shift_5  hour_shift_5  day_shift_5   \n",
      "1522060     51.09372     -5.84536            14.0          19.0          7.0  \\\n",
      "1522061     38.47765    -12.13535            15.0          22.0          7.0   \n",
      "1522062     49.77723     -4.50058            15.0          22.0          7.0   \n",
      "1522063     37.64190     11.32413            26.0           7.0          7.0   \n",
      "1522064     38.70218    -74.90653            15.0          22.0          7.0   \n",
      "\n",
      "           cog  heading  \n",
      "1522060  359.1        1  \n",
      "1522061   12.3       13  \n",
      "1522062  269.8      270  \n",
      "1522063    8.0        6  \n",
      "1522064  336.0      337  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "p7:          longitude  latitude\n",
      "1522060   -5.82223  52.19131\n",
      "1522061  -12.00502  38.96142\n",
      "1522062   -5.22042  49.71372\n",
      "1522063   10.78280  38.27895\n",
      "1522064  -75.13275  38.98635\n",
      "Mean Absolute Error: 11.19468797708796\n",
      "Root Mean Squared Error: 3.3458463767913735\n",
      "R2-score: 0.9961003255487773\n",
      "Variance Score: 0.9961003331931804\n",
      "19H:44M 23d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "import datetime\n",
    "from io import StringIO\n",
    "import random\n",
    "#!{sys.executable} -m pip install xgboost\n",
    "rs = 420\n",
    "random.seed(rs)\n",
    "\n",
    "print(datetime.datetime.today().strftime(\"%HH:%MM %dd\"))\n",
    "# Load datasets\n",
    "\n",
    "featuers = ['vesselId', 'hour', 'day', 'month', 'minute', 'vesselType', 'yearBuilt', 'length', 'breadth', 'CEU', 'DWT', 'GT', 'portLatitude', 'portLongitude', 'hour_sch', 'day_sch', 'month_sch', 'minute_sch', 'lat_shift_1', 'lon_shift_1', 'minute_shift_1', 'hour_shift_1', 'day_shift_1', 'month_shift_1', 'cog_1', 'heading_1', 'lat_shift_2', 'lon_shift_2', 'minute_shift_2', 'hour_shift_2', 'day_shift_2', 'month_shift_2', 'cog_2', 'heading_2', 'lat_shift_3', 'lon_shift_3', 'minute_shift_3', 'hour_shift_3', 'day_shift_3', 'month_shift_3', 'cog_3', 'heading_3', 'lat_shift_4', 'lon_shift_4', 'minute_shift_4', 'hour_shift_4', 'day_shift_4', 'month_shift_4', 'cog_4', 'heading_4', 'lat_shift_5', 'lon_shift_5', 'minute_shift_5', 'hour_shift_5', 'day_shift_5', 'month_shift_5', 'cog_5', 'heading_5', 'cog', 'heading', 'time_diff_1', 'time_diff_2', 'time_diff_3', 'time_diff_4', 'time_diff_5']\n",
    "featuers2 = ['longitude', 'latitude', 'vesselId', 'hour', 'day', 'month', 'minute', 'vesselType', 'length', 'breadth', 'CEU', 'DWT', 'GT', 'portLatitude', 'portLongitude', 'lat_shift_1', 'lon_shift_1', 'lat_shift_2', 'lon_shift_2', 'lat_shift_3', 'lon_shift_3', 'lat_shift_4', 'lon_shift_4', 'lat_shift_5', 'lon_shift_5', 'time_diff_1', 'time_diff_2', 'time_diff_3', 'time_diff_4', 'time_diff_5']\n",
    "target2 = ['cog', 'heading']\n",
    "vessel_encoder = LabelEncoder()\n",
    "timesteps = 6\n",
    "# test-test split\n",
    "liste = []\n",
    "for i in range(len(featuers)):\n",
    "    liste.append(pd.read_csv('x_data_'+str(i)+'.csv', sep=','))\n",
    "\n",
    "featuers = ['vesselId', 'hour', 'day', 'month', 'minute', 'vesselType', 'length', 'breadth', 'CEU', 'DWT', 'GT', 'portLatitude', 'portLongitude', 'lat_shift_1', 'lon_shift_1', 'lat_shift_2', 'lon_shift_2', 'lat_shift_3', 'lon_shift_3', 'lat_shift_4', 'lon_shift_4', 'lat_shift_5', 'lon_shift_5', 'cog', 'heading', 'time_diff_1', 'time_diff_2', 'time_diff_3', 'time_diff_4', 'time_diff_5']\n",
    "X = liste[0].join(liste[1:])\n",
    "X = X[featuers]\n",
    "y_1 = pd.read_csv('y_data_1.csv', sep=',')\n",
    "y_2 = pd.read_csv('y_data_2.csv', sep=',')\n",
    "y = y_2.join(y_1)\n",
    "\n",
    "z = y.join(X)\n",
    "x2 = z[featuers2]\n",
    "y2 = z[target2]\n",
    "\n",
    "\n",
    "print(\"p6:\", X.tail())\n",
    "print(\"p7:\", y.tail())\n",
    "#TODO: create a second model, this one predicts the cog and heading, then after the prediction on the ais_test with both models, use it to update the shifted values to create a new prediction using the original model\n",
    "\n",
    "X['vesselId'] = vessel_encoder.fit_transform(X['vesselId'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01, random_state=rs)\n",
    "\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(x2, y2, test_size=0.01, random_state=rs)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "X_train_scaled2 = scaler2.fit_transform(X_train2)\n",
    "X_val_scaled2 = scaler2.transform(X_val2)\n",
    "\n",
    "\n",
    "model = ExtraTreesRegressor(n_estimators=1, random_state=rs)\n",
    "model2 = ExtraTreesRegressor(n_estimators=1, random_state=rs)\n",
    "# Train a RandomForest model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "model2.fit(X_train_scaled2, y_train2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Absolute Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {np.sqrt(mse)}')\n",
    "print(f'R2-score: {r2_score(y_val, y_pred)}')\n",
    "print(f'Variance Score: {explained_variance_score(y_val, y_pred)}')\n",
    "\n",
    "# Use the same features as training\n",
    "X_0 = pd.read_csv('x_test.csv', sep=',')\n",
    "X_1 = pd.read_csv('x_test_1.csv', sep=',')\n",
    "X_2 = pd.read_csv('x_test_2.csv', sep=',')\n",
    "X_3 = pd.read_csv('x_test_3.csv', sep=',')\n",
    "X_4 = pd.read_csv('x_test_4.csv', sep=',')\n",
    "X_test = X_0.join([X_1, X_2, X_3, X_4])\n",
    "X_test = X_test[featuers]\n",
    "X_test['vesselId'] = vessel_encoder.transform(X_test['vesselId'])\n",
    "\n",
    "X_test.to_excel(\"x_test.xlsx\")\n",
    "# Scale the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Save the predictions\n",
    "predictions_df = pd.DataFrame(test_predictions, columns=['longitude', 'latitude'])\n",
    "last = X_test.join(predictions_df)\n",
    "X_test2 = X_test.join(predictions_df)\n",
    "\n",
    "for i in range(1, timesteps):  # Only 3 previous time steps\n",
    "    X_test2[f'lat_shift_{i}'] = X_test2.groupby('vesselId')['latitude'].shift(i)\n",
    "    X_test2[f'lon_shift_{i}'] = X_test2.groupby('vesselId')['longitude'].shift(i)\n",
    "    #X_test2[f'minute_shift_{i}'] = X_test2.groupby('vesselId')['minute'].shift(i)\n",
    "    #X_test2[f'hour_shift_{i}'] = X_test2.groupby('vesselId')['hour'].shift(i)\n",
    "    #X_test2[f'day_shift_{i}'] = X_test2.groupby('vesselId')['day'].shift(i)\n",
    "\n",
    "    X_test2[f'lat_shift_{i}'] = np.where(X_test2[f'lat_shift_{i}'].isna(), last[f'lat_shift_{i}'], X_test2[f'lat_shift_{i}'])\n",
    "    X_test2[f'lon_shift_{i}'] = np.where(X_test2[f'lon_shift_{i}'].isna(), last[f'lon_shift_{i}'], X_test2[f'lon_shift_{i}'])\n",
    "    #X_test2[f'minute_shift_{i}'] = np.where(X_test2[f'minute_shift_{i}'].isna(), last[f'minute_shift_{i}'], X_test2[f'minute_shift_{i}'])\n",
    "    #X_test2[f'hour_shift_{i}'] = np.where(X_test2[f'hour_shift_{i}'].isna(), last[f'hour_shift_{i}'], X_test2[f'hour_shift_{i}'])\n",
    "    #X_test2[f'day_shift_{i}'] = np.where(X_test2[f'day_shift_{i}'].isna(), last[f'day_shift_{i}'], X_test2[f'day_shift_{i}'])\n",
    "\n",
    "last = X_test2[featuers]\n",
    "X_test2 = X_test2[featuers2]\n",
    "X_test_scaled2 = scaler2.transform(X_test2)\n",
    "#TODO: use predictions_df in the slides for the next two predicts\n",
    "\n",
    "\n",
    "test_predictions2 = model2.predict(X_test_scaled2)\n",
    "headercogup = pd.DataFrame(test_predictions2, columns=target2)\n",
    "\n",
    "last['cog'] = headercogup['cog']\n",
    "last['heading'] = headercogup['heading']\n",
    "\n",
    "last.to_excel(\"last.xlsx\")\n",
    "\n",
    "last_scaled = scaler.transform(last)\n",
    "\n",
    "final_prediction = model.predict(last_scaled)\n",
    "\n",
    "predictions_df = pd.DataFrame(final_prediction, columns=['longitude_predicted', 'latitude_predicted'])\n",
    "predictions_df.to_csv('ais_test_predictions_1.csv', index=True)\n",
    "print(datetime.datetime.today().strftime(\"%HH:%MM %dd\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14H:17M 28d\n",
      "p1:          minute\n",
      "1666782      59\n",
      "1666783      59\n",
      "1666784      59\n",
      "1666785      59\n",
      "1666786      59\n",
      "p2:          portLongitude\n",
      "1666782     -81.496667\n",
      "1666783     -76.558889\n",
      "1666784     -79.927500\n",
      "1666785       0.000000\n",
      "1666786       0.000000\n",
      "p3:          vesselId\n",
      "1666782       459\n",
      "1666783       459\n",
      "1666784       459\n",
      "1666785       596\n",
      "1666786       637\n",
      "p4:          latitude\n",
      "1666782  49.71372\n",
      "1666783  49.71372\n",
      "1666784  49.71372\n",
      "1666785  38.27895\n",
      "1666786  38.98635\n",
      "p5:          longitude\n",
      "1666782   -5.22042\n",
      "1666783   -5.22042\n",
      "1666784   -5.22042\n",
      "1666785   10.78280\n",
      "1666786  -75.13275\n",
      "p6:          minute  portLongitude  vesselId  breadth     GT  length  month  \\\n",
      "1666782      59     -81.496667       459     38.0  72700  199.96      5   \n",
      "1666783      59     -76.558889       459     38.0  72700  199.96      5   \n",
      "1666784      59     -79.927500       459     38.0  72700  199.96      5   \n",
      "1666785      59       0.000000       596     27.0  25995  186.00      5   \n",
      "1666786      59       0.000000       637     32.0  59454  200.00      5   \n",
      "\n",
      "         sch_minute  yearBuilt  sch_hour  hour   CEU  portLatitude  \\\n",
      "1666782         0.0       2017       0.0    23  7429     31.140556   \n",
      "1666783         0.0       2017       0.0    23  7429     39.232500   \n",
      "1666784         0.0       2017       0.0    23  7429     32.822222   \n",
      "1666785         0.0       2003       0.0    23  1400      0.000000   \n",
      "1666786         0.0       2011       0.0    23  6215      0.000000   \n",
      "\n",
      "         vesselType  year  day      DWT  \n",
      "1666782        83.0  2024    7  18241.0  \n",
      "1666783        83.0  2024    7  18241.0  \n",
      "1666784        83.0  2024    7  18241.0  \n",
      "1666785        21.0  2024    7   7150.0  \n",
      "1666786        83.0  2024    7  18907.0  \n",
      "p7:          latitude  longitude\n",
      "1666782  49.71372   -5.22042\n",
      "1666783  49.71372   -5.22042\n",
      "1666784  49.71372   -5.22042\n",
      "1666785  38.27895   10.78280\n",
      "1666786  38.98635  -75.13275\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "import datetime\n",
    "import random\n",
    "rs = 420\n",
    "random.seed(rs)\n",
    "\n",
    "print(datetime.datetime.today().strftime(\"%HH:%MM %dd\"))\n",
    "# Load datasets\n",
    "\n",
    "\n",
    "vessel_encoder = LabelEncoder()\n",
    "\n",
    "# Select features and target\n",
    "features = ['vesselId', 'hour', 'day', 'month', 'year', 'minute', 'yearBuilt', 'length', 'vesselType', 'breadth', 'CEU', 'DWT', 'GT', 'portLatitude', 'portLongitude', 'sch_hour', 'sch_minute']#['cog', 'sog', 'rot', 'heading', 'navstat', 'latitude', 'longitude', 'vesselId', 'portId', 'hour', 'day', 'month', 'year', 'minute']\n",
    "target = ['latitude', 'longitude']  # Predicting next position (latitude, longitude)\n",
    "\n",
    "def feature_engineering(data):\n",
    "\n",
    "    data['vesselType'].fillna(83, inplace=True) #data['vesselType'].mode() -> dette er 83 men funker ikke??\n",
    "    data['yearBuilt'].fillna(data['yearBuilt'].median(), inplace=True)\n",
    "    data['length'].fillna(data['length'].median(), inplace=True)\n",
    "    data['breadth'].fillna(data['breadth'].median(), inplace=True)\n",
    "    data['CEU'].fillna(data['CEU'].median(), inplace=True)\n",
    "    data['DWT'].fillna(data['DWT'].median(), inplace=True)\n",
    "    data['GT'].fillna(data['GT'].median(), inplace=True)\n",
    "    data['portLatitude'].fillna(0, inplace=True)\n",
    "    data['portLongitude'].fillna(0, inplace=True)\n",
    "    data['sch_hour'].fillna(0, inplace=True)\n",
    "    data['sch_minute'].fillna(0, inplace=True)\n",
    "    return data\n",
    "\n",
    "# Handle missing values (if any)\n",
    "#ais_train = ais_train.dropna(subset=features + target) #ais_train.replace(to_replace='None', value=np.nan).dropna()\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_0 = pd.read_csv('x_data_0.csv', sep=',')\n",
    "print(\"p1:\", X_0.tail())\n",
    "X_1 = pd.read_csv('x_data_1.csv', sep=',')\n",
    "print(\"p2:\", X_1.tail())\n",
    "X_2 = pd.read_csv('x_data_2.csv', sep=',')\n",
    "print(\"p3:\", X_2.tail())\n",
    "X_3 = pd.read_csv('x_data_3.csv', sep=',')\n",
    "X_4 = pd.read_csv('x_data_4.csv', sep=',')\n",
    "X_5 = pd.read_csv('x_data_5.csv', sep=',')\n",
    "X_6 = pd.read_csv('x_data_6.csv', sep=',')\n",
    "X_7 = pd.read_csv('x_data_7.csv', sep=',')\n",
    "X_8 = pd.read_csv('x_data_8.csv', sep=',')\n",
    "X_9 = pd.read_csv('x_data_9.csv', sep=',')\n",
    "X_10 = pd.read_csv('x_data_10.csv', sep=',')\n",
    "X_11 = pd.read_csv('x_data_11.csv', sep=',')\n",
    "X_12 = pd.read_csv('x_data_12.csv', sep=',')\n",
    "X_13 = pd.read_csv('x_data_13.csv', sep=',')\n",
    "X_14 = pd.read_csv('x_data_14.csv', sep=',')\n",
    "X_15 = pd.read_csv('x_data_15.csv', sep=',')\n",
    "X_16 = pd.read_csv('x_data_16.csv', sep=',')\n",
    "X = X_0.join([X_1, X_2, X_3, X_4, X_5, X_6, X_7, X_8, X_9, X_10, X_11, X_12, X_13, X_14, X_15, X_16])\n",
    "y_1 = pd.read_csv('y_data_1.csv', sep=',')\n",
    "print(\"p4:\", y_1.tail())\n",
    "y_2 = pd.read_csv('y_data_2.csv', sep=',')\n",
    "print(\"p5:\", y_2.tail())\n",
    "y = y_1.join(y_2)\n",
    "\n",
    "print(\"p6:\", X.tail())\n",
    "print(\"p7:\", y.tail())\n",
    "X['vesselId'] = vessel_encoder.fit_transform(X['vesselId'])\n",
    "X = feature_engineering(X)\n",
    "model = RandomForestRegressor(n_estimators=1000, random_state=rs)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=rs)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Train a RandomForest model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Absolute Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {np.sqrt(mse)}')\n",
    "print(f'R2-score: {r2_score(y_val, y_pred)}')\n",
    "print(f'Variance Score: {explained_variance_score(y_val, y_pred)}')\n",
    "\n",
    "# Use the same features as training\n",
    "X_0 = pd.read_csv('x_test.csv', sep=',')\n",
    "X_1 = pd.read_csv('x_test_1.csv', sep=',')\n",
    "X_2 = pd.read_csv('x_test_2.csv', sep=',')\n",
    "X_3 = pd.read_csv('x_test_3.csv', sep=',')\n",
    "X_test = X_0 + X_1 + X_2 + X_3\n",
    "X_test['vesselId'] = vessel_encoder.transform(X_test['vesselId'])\n",
    "# Scale the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Save the predictions\n",
    "predictions_df = pd.DataFrame(test_predictions, columns=['longitude_predicted', 'latitude_predicted'])\n",
    "predictions_df.to_csv('ais_test_predictions.csv', index=True)\n",
    "print(datetime.datetime.today().strftime(\"%HH:%MM %dd\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
